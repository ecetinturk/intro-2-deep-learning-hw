{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykLMZlu29Ewh",
        "outputId": "5acf0257-c7c6-438c-a556-d24390c9aad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Homework 3\n",
        "if 1:\n",
        "  from google.colab import drive\n",
        "  #drive.flush_and_unmount()\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " if 0:\n",
        "    ! cp /content/drive/MyDrive/CaltechTinySplit.zip /content/\n",
        "    ! unzip CaltechTinySplit.zip -d /content/CaltechTinySplit"
      ],
      "metadata": {
        "id": "XW0oM_qk94JE"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2 # to work with images\n",
        "import glob # to load all images from a directory\n",
        "import matplotlib.pyplot as plt # to show image if we need to"
      ],
      "metadata": {
        "id": "hQiTSvP5_iY8"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resizeMyImage(i_image):\n",
        "  i_image = cv2.cvtColor(i_image, cv2.COLOR_BGR2RGB) # (blue,green,red) -> (red,green,blue)\n",
        "  i_image = cv2.resize(i_image,(128,128)) # image resized to 128x128(x3) size.\n",
        "  i_image = np.resize(i_image,(1,49152)) # image is resized to 1x49152 format (vector)  \n",
        "  i_image = np.concatenate((i_image,1), axis = None) # add bias\n",
        "  return i_image"
      ],
      "metadata": {
        "id": "sAbDZPgZzuQI"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#     -- [1] TASKS --\n",
        "#\n",
        "# 1. read images in 128x128x3 form\n",
        "# 2. convert them into 1x49152 form\n",
        "#    (convert into vector format)\n",
        "# 3. it will be the vector holding labels. (target vector)\n",
        "\n",
        "str_train_dir = \"/content/CaltechTinySplit/CaltechTinySplit/train/\"\n",
        "str_class0 = \"cannon\"\n",
        "str_class1 = \"cellphone\"\n",
        "#\n",
        "#   Above variables are not necessary anymore.\n",
        "#\n",
        "str_allJpg = \"/*.jpg\"\n",
        "\n",
        "image = [] # will hold one image at a time\n",
        "inputs1 = [] # will hold cannon images \n",
        "inputs2 = [] # will hold cellphone images\n",
        "t1 = [] # target vector for cannon\n",
        "t2 = [] # target vector for cellphone"
      ],
      "metadata": {
        "id": "OL3qyDfSw_uw"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cannon folder\n",
        "# will run 34 times\n",
        "for img in glob.glob('/content/CaltechTinySplit/CaltechTinySplit/train/cannon/*.jpg'):\n",
        "\n",
        "  image = cv2.imread(img) # image is stored in variable \"image\" in 128x128x3 format\n",
        "  inputs1.append(resizeMyImage(image)) # add the image at the end of inputs list\n",
        "  t1.append(0)"
      ],
      "metadata": {
        "id": "jHnHN4qNExK_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cellphone folder\n",
        "# will run 47 times\n",
        "for img2 in glob.glob('/content/CaltechTinySplit/CaltechTinySplit/train/cellphone/*.jpg'):\n",
        "\n",
        "  image2 = cv2.imread(img2) # image is stored in variable \"image\" in 128x128x3 format\n",
        "  inputs2.append(resizeMyImage(image2)) # add the image at the end of inputs list\n",
        "  t2.append(1)"
      ],
      "metadata": {
        "id": "9xIHxcXvExxK"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge both input and target values of cannon and cellphone\n",
        "inputs = inputs1 + inputs2\n",
        "t= t1 + t2"
      ],
      "metadata": {
        "id": "AW8OT1OvE0VB"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = np.float16( np.array(inputs) )\n",
        "targets = np.float16( np.array(t) )\n",
        "print(inputs)\n",
        "#print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXAAgfl0-SqJ",
        "outputId": "b69fd626-70c6-47e3-e58d-5b27e4ff0558"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[255. 255. 255. ... 255. 255.   1.]\n",
            " [255. 255. 255. ... 255. 255.   1.]\n",
            " [125. 131. 127. ... 227. 228.   1.]\n",
            " ...\n",
            " [255. 255. 255. ... 255. 255.   1.]\n",
            " [254. 254. 254. ... 250. 248.   1.]\n",
            " [254. 254. 254. ... 254. 254.   1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate 49153 weight values\n",
        "W =  np.random.rand(49153,)\n",
        "W = np.float16( np.array(W) )\n",
        "print(W)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sumBv5VT_DS0",
        "outputId": "c9da785c-ea7d-45d9-bce4-2159b67869df"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9893  0.0726  0.4104  ... 0.5796  0.695   0.11237]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle all values before training operation\n",
        "from sklearn.utils import shuffle\n",
        "inputs, t = shuffle(inputs, t)"
      ],
      "metadata": {
        "id": "99BW1G3fBxjX"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-defined functions\n",
        "def tanh(x):\n",
        " return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n",
        "\n",
        "def softplus(x):\n",
        " return np.log(1 + np.exp(x))\n",
        "\n",
        "def mish(x): # activation function\n",
        " return x * tanh(softplus(x))\n",
        "\n",
        "def dmish(x):\n",
        " omega = np.exp(3*x) + 4*np.exp(2*x) + (6+4*x)*np.exp(x) + 4*(1 + x)\n",
        " delta = 1 + pow((np.exp(x) + 1), 2)\n",
        " derivative = np.exp(x) * omega / pow(delta, 2)\n",
        " return derivative"
      ],
      "metadata": {
        "id": "b_8yN_54GLDk"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train perceptron\n",
        "def train_perceptron(inputs, targets, W, coef, iter):\n",
        "  for j in range(0, iter):\n",
        "    for i in range(0,8):\n",
        "        #feed- forward\n",
        "        X = inputs[i, :]\n",
        "        t = targets[i]\n",
        "        sum = np.dot(X,W)\n",
        "        y = mish(sum)\n",
        "        \n",
        "        ##feed- backward\n",
        "        error= t- y\n",
        "        dw = coef*error*dmish(y)*X\n",
        "        W = W + dw\n",
        "      \n",
        "    return W"
      ],
      "metadata": {
        "id": "y5nvD6Xo_GFt"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I have an issue in here when i'm trying to calculate new weight values.\n",
        "# (I have 0 values on input arrays so it should be cause throw an RuntimeWarning error.)\n",
        "# (I already tried images from different folders)\n",
        "\n",
        "#   -- [2]  --\n",
        "#    \n",
        "#    > Each training sample (input) is a pair of the form <x,t> ;\n",
        "#      where \n",
        "#           x is the vector of input values,\n",
        "#           t is label.   (0 or 1)\n",
        "#\n",
        "#    > Learning rate = 0.0001\n",
        "#    > Num. of iter. = 20000\n",
        "#\n",
        "\n",
        "import warnings\n",
        "#suppress warnings\n",
        "#warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"W_old:\", W)\n",
        "W_new = train_perceptron(inputs, t, W, 0.0001, 20000)\n",
        "print(\"W_new:\", W_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjd0fAbi_K9d",
        "outputId": "7592726a-5c69-4de9-b379-434070f23aac"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W_old: [0.5835 0.8687 0.7607 ... 0.1755 0.9717 0.5273]\n",
            "W_new: [nan nan nan ... nan nan nan]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving new weight values\n",
        "np.save('W_new.npy', W_new) # save \n",
        "weights = np.load('W_new.npy') # load"
      ],
      "metadata": {
        "id": "fFR4b3QBA5Kb"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test perceptron\n",
        "def testPerceptron(sample_test, weights):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for i in range(0,8):\n",
        "        X = inputs[i, :]\n",
        "        t = targets[i]\n",
        "        y_true.append(t)\n",
        "        sum = np.dot(X,weights)\n",
        "        y = mish(sum)\n",
        "        y = np.round(y)\n",
        "        y_pred.append(y)  \n",
        "         \n",
        "    return y_true, y_pred"
      ],
      "metadata": {
        "id": "_r3ejoTaA74f"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true, y_pred = testPerceptron(inputs, weights)"
      ],
      "metadata": {
        "id": "Z0lixGtfA9AV"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the true values that i calculated\n",
        "print(y_true)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0btQmxgBD8c",
        "outputId": "900c1756-4b7f-45b0-a2ce-ad4318645764"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the predicted values that i wanted to reach\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb9IxcdFBEqZ",
        "outputId": "2d44a6b8-7a54-4ab8-bf42-d8e9514d529d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nan, nan, nan, nan, nan, nan, nan, nan]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# i could not calculated these calculations because i have 0 values on input arrays\n",
        "# i could not resolve that problem :(\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "conf = confusion_matrix(y_true, y_pred)\n",
        "print(conf)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "7c8wO1SUBHNU",
        "outputId": "84f73672-c474-4ed4-a2f6-5db8c71c4139"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-4b9809d181b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#conf = confusion_matrix(y_true, y_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"f\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"continuous\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    114\u001b[0m             raise ValueError(\n\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[0;32m--> 116\u001b[0;31m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 )\n\u001b[1;32m    118\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
          ]
        }
      ]
    }
  ]
}